---
title: "Propensity Score Weighting and Generalized Boosted Regression in R"
author: "Peter Sun"
date: "September 30, 2021"
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
header-includes:
- \usepackage{float}
- \usepackage{pdflscape}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage{pgfornament}
- \usepackage{mathtools}
- \usepackage{amsmath,amsthm,amssymb}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
---

\newpage
# Load Packages

Stata DTA files can be imported directly into R using the `haven` and `sjlabelled` packages. 

Propensity score weighting can be accomplished with base R. However, we need the `lmtest` and `sandwich` packages to estimate clustered covariance matrices in this example. Using these packages, we can obtain estimates and standard errors that are identical to Stata's `regress` program.

Generalized boosted regression requires the `gbm` package.

Finally, the `tidyverse` package can be optionally loaded for its convenient data manipulation and plotting functions.

```{r message=F, warning=F, error=F}
library(tidyverse)
library(haven)
library(sjlabelled)
library(lmtest)
library(sandwich)
library(gbm)
```

# Propensity Score Weighting

## Description of Dataset

This dataset is from a study that investigates intergenerational dependence on welfare and its relation to child academic achievement.^[Hofferth, S., Stafford, F. P., Yeung, W. J., Duncan, G. J., Hill, M. S., Lepkowski, J., et al. (2001). *Panel study of income dynamics, 1968–1999: Supplemental files (computer file), ICPSR version*. Ann Arbor: University of Michigan Survey Research Center.]

The dependent variable is `lwss97` or "letter-word identification" score, and the treatment condition is `kuse` or children who used Aid to Families With Dependent Children (AFDC). The covariates are:

- `male`: Child's Gender: Male (Reference: Female)
- `black`: Child's Race: African American (Reference: Other)
- `age97`: Child's Age in 1997
- `pcged97`: Caregiver's Education in 1997 (Years of Schooling)
- `mratio96`: Ratio of Family Income to Poverty Line in 1996

Additionally, `pcg_id` is a cluster variable that identifies children nested within families.

## Load Data with Propensity Scores

```{r}
d <- read_dta("data/chpt5_2_original.dta") %>%
  haven::zap_formats() %>%
  sjlabelled::remove_all_labels() %>%
  as_tibble()
head(d$ps)
```

## Estimate ATE and ATT Weights

Here we calculate separate weights for estimating the average treatment effect (ATE) and the average treatment effect for the treated (ATT).

For ATE, the weight estimates are calculated as follows for the treatment group:

$$
\omega = \frac{1}{\hat{e}(x)}
$$

And for the control group:

$$
\omega = \frac{1}{1 - \hat{e}(x)}
$$

For ATT, the weight is 1 for a treated case. The weight for a comparison case is:

$$
\omega = \frac{\hat{e}(x)}{1 - \hat{e}(x)}
$$

```{r message=FALSE, warning=FALSE}
d.weights <- d %>%
  mutate(ate_w = ifelse(kuse == 0, 1/(1-ps), 1/ps),
         att_w = ifelse(kuse == 0, ps/(1-ps), 1))
```

## Outcome Analysis

### Weighted Regression with ATE Weights

After creating the weights, use the `weights` argument in `lm()` to run a weighted outcome analysis and `lmtest::coeftest()` to control for clustering effects.

This analysis showed that children who used Aid to Families With Dependent Children (AFDC) had an average letter-word identification score that was 5.16 points lower than children who never used AFDC, $p < .01$.

```{r message=FALSE, warning=FALSE}
m3 <- lm(lwss97 ~ kuse + male + black + age97 + pcged97 + mratio96, 
         data = d.weights, weights = ate_w) 
lmtest::coeftest(m3, vcov. = vcovCL(m3, cluster = d.weights$pcg_id))
```

### Weighted Regression with ATT Weights

When considering only individuals assigned to the treatment condition, children who used AFDC had an average letter-word identification score that was 4.62 points lower than children who never used AFDC, $p < .01$.

```{r message=FALSE, warning=FALSE}
m4 <- lm(lwss97 ~ kuse + male + black + age97 + pcged97 + mratio96, 
         data = d.weights, weights = att_w)
lmtest::coeftest(m4, vcov. = vcovCL(m4, cluster = d.weights$pcg_id))
```

## Check Imbalance

To assess balance before and after propensity score weighting, use logistic regression for dummy covariates and OLS regression for continuous covariates. Some examples are included below, and the full code can be found in Section 7.3.1 of the PSA-R code.

In model `c5` below, the treatment dummy variable is significant, meaning that there is no sufficient balance after the propensity score weighting.

To assess balance before propensity score weighting, remove the `weights` argument.

```{r}
c1 <- glm(male ~ kuse, family = quasibinomial, data = d.weights, weights = ate_w)
lmtest::coeftest(c1, vcov. = vcovCL(c1, cluster = d.weights$pcg_id))
c2 <- glm(male ~ kuse, family = quasibinomial, data = d.weights, weights = att_w)
lmtest::coeftest(c2, vcov. = vcovCL(c2, cluster = d.weights$pcg_id))

c5 <- lm(age97 ~ kuse, weights = ate_w, data = d.weights)
lmtest::coeftest(c5, vcov. = vcovCL(c5, cluster = d.weights$pcg_id))
c6 <- lm(age97 ~ kuse, weights = att_w, data = d.weights)
lmtest::coeftest(c6, vcov. = vcovCL(c6, cluster = d.weights$pcg_id))
```

\newpage
# Estimate Propensity Scores Using Generalized Boosted Regression

## Load Data and Sort

Generalized boosted regression (GBR) is an iterative method for creating propensity scores. Therefore, to create reproducible results, we need to use the `set.seed()` function in R.

After importing the data, missing data is deleted listwise, and the data is sorted in a random order. Note the use of the `set.seed()` function to create the same set of random numbers from the uniform distribution.

According to the `gbm` package vignette, if the data is sorted in a systematic way, then the data should be shuffled before running `gbm`.

```{r}
# Correction: Randomly shuffle the data before fitting GBM model
set.seed(1000)
d2 <- read_dta("data/g3aca1.dta") %>%
  haven::zap_formats() %>%
  sjlabelled::remove_all_labels() %>%
  as_tibble() %>%
  select(intbl, ageyc, fmale, blck, whit, hisp, pcedu, ipovl, pcemft, fthr,
         dicsagg2, dicsint2, dccereg2, dccscom2, dccpros2, draggr2) %>%
  drop_na() %>%
  add_column(runif = runif(nrow(.))) %>%
  arrange(runif)
```

## Fit Generalized Boosted Regression Model

The `gbm::gbm()` function has many arguments that can be fine-tuned. See `?gbm` for a detailed description of each argument.

A summary of the fitted model provides us with *relative influence*, which is the percentage of log likelihood explained by each input variable.

The GBM showed that `blck` had the strongest influence on the likelihood function (33.7%), followed by `ageyc` (16.3%) and `draggr2` (9.4%).

```{r message=F, fig.width=6, fig.height=3.5, fig.align="center"}
# Correction: Remove the column of random numbers from the formula
f5 <- as.formula(paste("intbl ~ ", paste(names(select(d2, -intbl, -runif)), 
                                         collapse = " + ")))
set.seed(1000)
m5 <- gbm::gbm(formula = f5,
          data = d2,
          distribution = "bernoulli",
          n.trees = 1000, # number of trees to fit
          train.fraction = 0.8, # a random 80% subsample for estimation
          interaction.depth = 4, # allow all four-way interactions
          shrinkage = 0.0005) # small shrinkage to ensure smooth fit
summary(m5)
```

## Estimate Propensity Scores

After fitting the model, propensity scores can be generated by using the `predict.gbm()` function.

```{r}
psb <- gbm::predict.gbm(m5, data = d2, type = "response") # Create ps
head(psb)
```

\newpage
## Plot Propensity Score Distributions

As seen in the figure below, the propensity scores estimated by GBM has sufficient overlap between the control and treatment groups (i.e., "common support"), and the distributions are similar.

```{r fig.width=6, fig.height=3.5, fig.align="center"}
d2 %>%
  mutate(psb = psb,
         intbl = factor(intbl, labels = c("Control", "Treatment"))) %>%
  ggplot(aes(x = psb, color = intbl)) + theme_classic() +
  geom_density(size = 1) + xlim(0, 1) + ylim(0, 22) +
  labs(x = "Predicted Probability", y = "Density",
       title = "Propensity Scores Using Generalized Boosted Regression", 
       color = "Treatment") +
  theme(legend.position = c(0.9, 0.85))
```

## Summary Statistics of Propensity Scores

```{r}
summary(psb)
```

\newpage
# Bonus: Using the WeightIt Package

## Estimate ATE and ATT Weights

```{r message=F, fig.width=6, fig.height=3.5, fig.align="center"}
# Load Packages
library(WeightIt)
library(cobalt)

# Estimate ATE and ATT weights and Check with Previous Results
ate_w2 <- WeightIt::get_w_from_ps(ps = d$ps,
                                  treat = d$kuse,
                                  estimand = "ATE")
table(ate_w2 == d.weights$ate_w)
att_w2 <- WeightIt::get_w_from_ps(ps = d$ps,
                                  treat = d$kuse,
                                  estimand = "ATT")
table(att_w2 == (d.weights$ate_w * d.weights$ps))
```

## Estimate Propensity Scores using Generalized Boosted Regression

```{r message=F, fig.width=6, fig.height=3.5, fig.align="center"}
# Estimate PS with GBM
set.seed(1000)
m5.alt <- WeightIt::weightit(
  formula = f5,
  data = d2,
  method = "gbm",
  estimand = "ATE",
  distribution = "bernoulli",
  stop.method = "es.mean",
  n.trees = 10000, # different
  nTrain = 0.8 * nrow(d2), # different
  interaction.depth = 4,
  shrinkage = 0.0005
)
```

\newpage
## Check Imbalance with the Cobalt Package

The standardized mean difference (SMD) is a commonly used balance measure. It is calculated as the difference in means of a covariate across the treatment groups, divided by the standard deviation in the treated group. Stuart et al. (2013) recommend 0.1 or 0.25 as reasonable cut-offs for acceptable standardized biases.^[Stuart, E. A., Lee, B. K., & Leacy, F. P. (2013). Prognostic score–based balance measures for propensity score methods in comparative effectiveness research. *Journal of Clinical Epidemiology*, 66(8 0), S84-S90.e1. https://doi.org/10.1016/j.jclinepi.2013.01.013]

Using the more stringent 0.1 cut-off point, it can be seen below that balance has been achieved in most, but not all, of the covariates:

```{r message=F, fig.width=6, fig.height=3.5, fig.align="center"}
cobalt::love.plot(m5.alt, thresholds = c(m = .1), binary = "std", abs = T) +
  labs(title = "Covariate Balance (ATE)")
```
